\chapter{The \tt{R} package \tt{gmvjoint}}\label{cha:appendix-gmvjoint}
The aim of the work presented (particularly in Chapter \ref{cha:flexible}) lead to development of the \tt{R} package \tt{gmvjoint}, which is available on CRAN. Since the package was used extensively in generation of all presented results, a brief overview of all `major' functions is given in this short Appendix.\\All source code is available at \url{https://github.com/jamesmurray7/gmvjoint}.

\section{Data generation: \tt{simData}}\label{sec:appendix-gmvjoint-simData}
The facility to generate data under a joint model is vitally important to validation of the proposed method, and we simulate copious amounts of said data in the work presented in the main body. The bespoke function \tt{simData} allows us to simulate under a wide variety of scenarios which may be of interest. 

Underlying features of the data such as the sample size, the maximal number of follow-up measurements (\ie $r$ in Section \ref{sec:approx-simsetup-proper}), the length of follow-up ($\kappa$ in the same section) and whether or not the follow-up times are regularly spaced or randomly drawn from $\mathrm{Unif}[0,\kappa]$ can be controlled from the call to \tt{simData} by arguments \tt{n}; \tt{ntms}; \tt{fup}; and \tt{regular.times}, respectively.

For parameter values, the true fixed effects $\bb$ are supplied as a $K\times4$ \textit{matrix}, wherein each row contains $\bb_k$, providing the true fixed effect for the intercept, time, standard normal realization and random Bernoulli draw for the $\kth$ response. The variance-covariance matrix on random effects $\D$ is supplied as a matrix, which is internally checked for positive semi-definiteness. The degrees of freedom of the random effects can be supplied by the \tt{dof} argument. The conditional distribution of the response $\Y{_k}|\b{_k}\ \forall\ i=1,\dots,n$ is provided as a \tt{list} of length $K$ and can take values ``\tt{gaussian}''; ``\tt{poisson}''; ``\tt{binomial}''; ``\tt{Gamma}''; ``\tt{negbin}''; and ``\tt{genpois}''.

The random effects specification for each argument can be set by argument \tt{random.formula}, which takes a \tt{list} of \tt{formula} objects (only random intercept, and intercept-and-slope are implemented, though). Dispersion parameters $\bs$ are provided as a \tt{list} of length $K$, where each element corresponds to the dispersion model explained in Section \ref{eq:flexible-dispmodel} and outlined for each family in Table \ref{tab:flexible-distribs}; time-varying specifications can be supplied by simply providing a vector in the $\kth$ position and corresponding item in \tt{disp.formulas} set to an appropriate \tt{formula} object. 

Finally, survival times are generated by the methodology outlined in Sections \ref{sec:sim-survtime} and \ref{sec:sim-joint}. A $K$-vector of parameters \tt{gamma} specifies the association held by the random effects for each response, and time-invariant survival parameters are provided as a vector of length 2 \tt{zeta}, corresponding to the standard normal realization and Bernoulli draw (\ie the baseline covariates). The baseline hazard is additionally controlled by argument \tt{theta}. 


\section{Workhorse function: \tt{joint}}\label{sec:appendix-gmvjoint-joint}
The main workhorse function is \tt{joint}. This takes in a few key arguments:

\textbf{\tt{long.formulas}}: A \tt{list} containing the $K$ \tt{formula}s constructing the GLMM sub-models in desired joint model. These must match the syntax expected by \tt{glmmTMB} \citep{R-glmmTMB}:
\begin{lstlisting}
<response> ~ <fixed effect specification> + (<random effect specification | <grouping variable>)
\end{lstlisting}
\textbf{\tt{surv.formula}}: A \tt{formula} object usable by \tt{coxph} from the \tt{survival} package \citep{R-survival}:
\begin{lstlisting}
Surv(<survival time>, <event indicator>) ~ <survival covariates>
\end{lstlisting}
\textbf{\tt{data}}: A \tt{data.frame} object containing all necessary variables.\\
\textbf{\tt{family}}: A \tt{list} of length $K$, with each element a character string matching one of ``\tt{gaussian}''; ``\tt{poisson}''; ``\tt{binomial}''; ``\tt{Gamma}''; ``\tt{negbin}''; or ``\tt{genpois}''. The $\kth$ element of \tt{family} `matches up' with the corresponding $\kth$ \tt{long.formulas} entry.\\
\textbf{\tt{disp.formula}}: A \tt{list} of length $K$, each element specifying the dispersion \tt{formula} required for each sub-model. Elements are ignored if corresponding family doesn't model dispersion; if left untouched then intercept-only dispersion is modelled.\\
\textbf{\tt{control}}: A \tt{list} specifying control arguments. This allows for (amongst other things) changing of convergence criterion outlined in Section \ref{sec:approx-convcrit}; the step-size in numerical differentiation routines (\eg central differencing in Appendix \ref{sec:appendix-numdiff}); and increasing/decreasing the number of quadrature nodes.

The \tt{joint} function then sends these arguments through many internal functions to obtain initial conditions; execute an EM algorithm until convergence; and then undergo post-processing before finally returning an object with class \tt{joint}, which we give an outline of in the next section.

\section{\tt{R} object of class \tt{joint} and its S3 methods}\label{sec:appendix-gmvjoint-joint-object}
Once the \tt{joint} object has been successfully fit, it returns an \tt{R} object with class \tt{joint}. Within \tt{R}, a style of pseudo-object oriented programming functions called `S3 methods'\footnote{Named as such as they were first introduced in version 3 of \tt{R}'s predecessor, \tt{S}.} are available; these work essentially by inspecting the class on a given object when called using a reserved generic function name, \eg \tt{print}, and then executing a specific function written for said specific class \tt{joint}. 

The user can \tt{print} a \tt{joint} object to \eg the \tt{R} console window by simply typing its object name, where the user then observes association parameter estimates, along with information about the model and the data. A more in-depth representation of the joint model is provided by the \tt{summary} S3 method, which prints, amongst other items, \textit{all} parameter estimates, their standard errors and $p$-values. \LaTeX-ready tables are provided by the \tt{xtable} S3 method. The user can extract specific `parts' of the joint model such as: The fixed effects by \tt{fixef}; random effects by \tt{ranef}; variance-covariance matrix by \tt{vcov}; and the log-likelihood and AIC by \tt{logLik} and \tt{AIC}, respectively. 

Toy exemplar usage of \tt{gmvjoint} which demonstrates data generation, model fitting, and these S3 methods is provided in the next section.

\section{Limitations of \tt{gmvjoint}}\label{sec:appendix-gmvjoint-limitations}
\tt{gmvjoint} is very much fledgling software developed to facilitate and transportability of the novel methodologies introduced. With this being said, there are a few limitations with the software, here we list those the interested reader may wish to take into consideration:
\begin{itemize}
    \item Owing to the steps taken in generation of design matrices, the survival term can not contain interactions.
    \item The time variable and subject identifier \textbf{must} be called \tt{time} and \tt{id} in the \tt{data} provided by the user.
    \item Data must be balanced (\ie no missing values), else \tt{joint} throws an error once the underlying \tt{C++} routines are called.
    \item Models for the conditional expectation of the response, as well as dispersion models, are not flexibly specified (see Table \ref{tab:flexible-distribs} in Chapter \ref{cha:flexible}), whereas one would usually be able to specify link functions herein \eg \tt{family=`binomial'(link=`log')}.
\end{itemize}

\section{Example use of \tt{gmvjoint}}\label{sec:appendix-gmvjoint-exampleprogram}
In the upcoming example, \colorbox{backcolour}{\tt{typewriter font with a grey background}} denotes code which is executed in \tt{R}, with \tt{typewriter font with no background} the output. We begin by simulating some data matching the simulation study specification carried out in Section \ref{sec:flexible-sim-triv}
\begin{lstlisting}
library(gmvjoint)
set.seed(1995)
# Default values as outlined in Section 4.5.2
D <- diag(c(0.25, 0.05, 0.50, 0.09, 2.00))
D[1,3] <- D[3,1] <- D[1,5] <- D[5,1] <- D[3,5] <- D[5,3] <- 0.125
sim.dat <- simData(
  beta = rbind(
    c(-2, .1,-.1,.2), # Attached to Gaussian response
    c( 2,-.1, .1,.2), # Poisson
    c( 1, -1,  1,-1)  # Binomial
  ), D = D,
  # Survival parameters (zeta is attached to the binary x_2 only)
  gamma = c(0.5, -0.5, 0.5), zeta = c(0, -0.2),
  ntms = 10L, n = 500L,
  family = list("gaussian", "poisson", "binomial"),
  # Residual variance for Gaussian term
  sigma = list(0.16, 0, 0), 
  # Random intercept only for the binary response
  random.formulas = list(~time, ~time, ~1)
)
# This generates a list of the "full" longitudinal and "survival" data.
# Taking the former forwards, simulated data preview...
sim.dat <- sim.dat$data
head(sim.dat)  
\end{lstlisting}
\vspace*{-5mm}
\begin{small}
\begin{verbatim}
   id      time       cont bin        Y.1 Y.2 Y.3  survtime status
1   1 0.0000000  1.0607633   1 -2.1009485   7   0 2.5608142      1
2   1 0.5555556  1.0607633   1 -1.5464562  10   0 2.5608142      1
3   1 1.1111111  1.0607633   1 -2.2722669   8   0 2.5608142      1
4   1 1.6666667  1.0607633   1 -0.9587497   5   0 2.5608142      1
5   1 2.2222222  1.0607633   1 -1.0971355   6   0 2.5608142      1
11  2 0.0000000 -0.3355017   1 -2.5143327  11   0 0.9009338      1
\end{verbatim}
\end{small}
Next, we define formula objects we use to fit the joint model, and fit the model using the workhorse function \tt{joint}. Formulae are defined outside of the call to \tt{joint} for readability, although they could equally be simply defined `within' this function call. 
\begin{lstlisting}
longs <- list(
  Y.1 ~ time + cont + bin + (1 + time|id),
  Y.2 ~ time + cont + bin + (1 + time|id),
  Y.3 ~ time + cont + bin + (1|id)
)
surv <- Surv(survtime, status) ~ bin
fit <- joint(
  long.formulas = longs, surv.formula = surv,
  data = sim.dat, family = list("gaussian", "poisson", "binomial")
)
# S3 method for printing
fit
\end{lstlisting}
\vspace*{-5mm}
\begin{small}
\begin{verbatim}
Number of subjects: 500
Number of events: 90 (18.00%)

===================
Model specification
===================
Multivariate longitudinal process specifications: 
Y.1 (gaussian): ~ time + cont + bin + (1 + time | id)
Y.2 (poisson): ~ time + cont + bin + (1 + time | id)
Y.3 (binomial): ~ time + cont + bin + (1 | id)

Survival sub-model specification: 
Surv(survtime, status) ~ bin

Association parameter estimates: 
       Y.1        Y.2        Y.3 
 0.5022092 -0.4497374  0.3773821     
\end{verbatim}
\end{small}
With the fitted joint model, we can then enact several S3 methods as alluded to in the previous section. These are presented across several code-output `chunks' which follow.
\begin{lstlisting}
# S3 method for model summary
summary(fit)
\end{lstlisting}
\vspace*{-5mm}
\begin{small}
\begin{verbatim}
Number of subjects: 500
Number of events: 90 (18.00%)
Number of responses: 3; dimension of random effects: 5
Median [IQR] profile length: 10 [9, 10]

Model fit statistics ----
  log.Lik       AIC       BIC 
-17153.14  34370.27  34609.33 
Degrees of freedom: 32

Longitudinal processes ----
Y.1 (Gaussian)
Call:
Y.1 ~ time + cont + bin + (1 + time | id) 
                               SE       Z p-value   2.5%  97.5%
Y.1_(Intercept) -2.01205420 0.040 -49.885   0.000 -2.091 -1.933
Y.1_time         0.12012154 0.012   9.774   0.000  0.096  0.144
Y.1_cont        -0.08178707 0.027  -3.044   0.002 -0.134 -0.029
Y.1_bin          0.22080319 0.053   4.184   0.000  0.117  0.324
sigma^2_1        0.15537859 0.004  38.110   0.000  0.147  0.163

Y.2 (Poisson)
Call:
Y.2 ~ time + cont + bin + (1 + time | id) 
                               SE      Z p-value   2.5%  97.5%
Y.2_(Intercept)  2.07276941 0.045 45.933    0.00  1.984  2.161
Y.2_time        -0.09997427 0.015 -6.741    0.00 -0.129 -0.071
Y.2_cont         0.12526977 0.034  3.679    0.00  0.059  0.192
Y.2_bin          0.12348258 0.066  1.882    0.06 -0.005  0.252

Y.3 (Binomial)
Call:
Y.3 ~ time + cont + bin + (1 | id) 
                             SE       Z p-value   2.5%  97.5%
Y.3_(Intercept)  1.109736 0.133   8.368       0  0.850  1.370
Y.3_time        -1.024679 0.046 -22.045       0 -1.116 -0.934
Y.3_cont         1.021418 0.088  11.609       0  0.849  1.194
Y.3_bin         -1.377318 0.155  -8.909       0 -1.680 -1.074

Event-time sub-model: ----
Call: Surv(survtime, status) ~ bin
                        SE      Z p-value   2.5%  97.5%
zeta_bin  -0.2334932 0.236 -0.991   0.322 -0.695  0.228
gamma_Y.1  0.5022092 0.117  4.302   0.000  0.273  0.731
gamma_Y.2 -0.4497374 0.106 -4.249   0.000 -0.657 -0.242
gamma_Y.3  0.3773821 0.098  3.838   0.000  0.185  0.570

Computation summary: ----
Number of EM iterations: 7,
Time spent in EM algorithm: 5.89s
Total computation time: 10.34s.
\end{verbatim}
\end{small}
\begin{lstlisting}
# Fixed effects (longitudinal process, the default)
fixef(fit)
# and the survival
fixef(fit, what = "surv")
\end{lstlisting}
\vspace*{-5mm}
\begin{small}
\begin{verbatim}
Y.1_(Intercept)        Y.1_time        Y.1_cont         Y.1_bin Y.2_(Intercept)        Y.2_time        Y.2_cont         Y.2_bin Y.3_(Intercept) 
    -2.01205420      0.12012154     -0.08178707      0.22080319      2.07276941     -0.09997427      0.12526977      0.12348258      1.10973561 
       Y.3_time        Y.3_cont         Y.3_bin 
    -1.02467854      1.02141792     -1.37731756     
  
  zeta_bin    gamma_1    gamma_2    gamma_3 
-0.2334932  0.5022092 -0.4497374  0.3773821     
\end{verbatim}
\end{small}
\begin{lstlisting}
# Random effects estimates (first five subjects only)
ranef(fit)[1:5,]
\end{lstlisting}
\vspace*{-5mm}
\begin{small}
\begin{verbatim}
     Y.1_(Intercept)     Y.1_time Y.2_(Intercept)    Y.2_time Y.3_(Intercept)
[1,]     -0.05814563  0.199440189      -0.1672700 -0.08070501      -1.2257325
[2,]     -0.44714415 -0.007098271      -0.0673282 -0.13425896      -0.3250280
[3,]     -1.13464512  0.240416941      -1.2778383 -0.11237033      -0.1985621
[4,]     -0.46574655 -0.255950104      -0.8261767 -0.08962955       2.3944808
[5,]      0.72637241 -0.113025740       0.7535331 -0.07375549      -2.0905239
\end{verbatim}
\end{small}
\begin{lstlisting}
# Model log-likelihood and AIC
logLik(fit)
AIC(fit)
\end{lstlisting}
\vspace*{-5mm}
\begin{small}
\begin{verbatim}
`log Lik.' -17153.14 (df=32)
34370.27
\end{verbatim}
\end{small}
\section{Usage of \tt{C++} to reduce computation time}\label{sec:appendix-gmvjoint-cpp}
In Section \ref{sec:approx-implementation} we noted that packages which allow for integration of \tt{C++} in \tt{R} are used to overcome computational bottlenecks. The interfacing between \tt{R} and compiled languages (such as \tt{C++}) is becoming the norm, with an estimated $\approx13\%$ of all packages on \tt{CRAN} using \tt{Rcpp} \citep{R-Rcpp}. 

Briefly in this section we provide an example of the performance gains with respect to computation time we observed in development of the methods in Chapters \ref{cha:approx} and \ref{cha:flexible}. The update for survival parameters is a known bottleneck \citep{Hickey2018}: The conditional expectation \eqref{eq:approx-Mstep-PhiObjective} needs to be numerically differentiated $n$ times at each EM iteration. 

We consider three different strategies to obtaining the updated survival parameters $\hat{\bm{\Phi}}$ \eqref{eq:methods-survMstep}. We arbitrarily chose the univariate joint model we fit to (log) serum bilirubin in the PBC application in Section \ref{sec:pbc-jointmodelling-univs}. The first method implements the objective conditional expectation \eqref{eq:approx-Mstep-PhiObjective}, along with forward and central differencing routines -- as outlined in Appendix \ref{sec:appendix-numdiff} -- all in \tt{C++}; the next implements the conditional expectation in \tt{C++}, but calls the \tt{R} package \tt{pracma} \citep{R-pracma} to carry out this numerical differentiation. Lastly, we consider an implementation written in \tt{R} entirely.

The \tt{R} package \tt{microbenchmark} \citep{R-microbenchmark} is used to replicate each strategy 250 times and benchmark the elapsed times against one another; a violin plot of elapsed times is given in Figure \ref{fig:appendix-gmvjoint-elapsed}. Here we notice that simply rewriting the conditional expectation in \tt{C++} corresponds to a near three-fold decrease in average computation time ($602.96\rightarrow208.09$ms), and further implementing the numerical differentiation into \tt{C++} approximately a 2-fold decrease ($208.09\rightarrow110.17$ms). Although these gains may appear small, one must consider that these will all only increase with $n$. In addition, this benchmarking solely considered `one iteration' and in reality these performance gains will `add up' over the full implementation of the iterative EM algorithm.

\begin{figure}
    \centering
    \includegraphics{Figures/CppR.png}
    \caption{Violin plot of elapsed times taken for 250 benchmarked replicates of updates to the survival parameter vector $\hat{\bm{\Phi}}$. A log scale is employed on the $x$-axis between ticks.}
    \label{fig:appendix-gmvjoint-elapsed}
\end{figure}
